### python 3 codes ###
# remotely use Pitt HTC cluster
# python=python/anaconda3.8-2020.11 (Python 3.8.5.final.0); pandas=1.1.3; numpy=1.19.2;

### one_Barcode vs multiple_TSSs filter ###
# For those barcodes that match to multiple TSS variants,
# if #reads of major TSS-Bar of this barcode is >= 90% total reads containing this barcode,
    # keep this major TSS-Bar, drop others
# Otherwise, drops all reads related to this barcode

# Input-1: [DTmerge-MASTER-all_final-info_table.csv] containing information for all MASTER samples
# Input-2s: UMI-tools output files [*-TssCXed-mockBarCXonTss-sorted-grouped.tsv] generated by <6-UMItools-TssCXed-Bar_CX.slurm>
    # 9 columns
# Input-3s: TSS Index file [*-TssCXed-Tss_idx.txt] generated by <5-MkMockSam-TssCXed-BarOnTss.py>

# Output-1s: [*-CXed-Tss_Bar_Cnt-Mtx.txt], matrix after CX but before one_Barcode vs multiple_TSSs filter
    # 3 columns, [TSS] \t [Barcode_Ds] \t [DNA_Count]
# Output-2s: [*-CXed-BarFltr-Tss_Bar_Cnt-Mtx.txt], matrix after one_Barcode vs multiple_TSSs filter
    # 3 columns, [TSS] \t [Barcode_Ds] \t [DNA_Count]
# Output-3s: [*-CXed-BarFltr_kpInfo.txt], information for barcodes that match to multiple TSSs but CAN pass filter
    # 2 columns, [Major_Bar_Count] \t [Total_Bar_Count]
# Output-4s: [*-CXed-BarFltr_drpInfo.txt], information for barcodes that match to multiple TSSs but NOT pass filter
    # 2 columns, [Major_Bar_Count] \t [Total_Bar_Count]
# Output-5: [7-BarMltTss_fltr-info.csv], details for processed samples

import datetime
job_start = datetime.datetime.now()
print(job_start)

import pandas as pd
print("pandas version:", pd.__version__)
print()

cmn_folder = '/bgfs/ckaplan/Yunye/0-common_files/'
inp_folder = '/bgfs/ckaplan/Yunye/3-TSS_sequence_library/1-WT-DNAseq-TxGen_18179Kap/5_6-TssCXed-BarOnTss/'
out_folder = '/bgfs/ckaplan/Yunye/3-TSS_sequence_library/1-WT-DNAseq-TxGen_18179Kap/7-BarMltTss_fltr/'

smp_info = pd.read_csv(cmn_folder+'DTmerge-MASTER-all_final-info_table.csv', na_filter= False) # w/o filling empty cells as NaN
# to only process samples with DNAseq:
smp_info = smp_info[smp_info['super_id']<=12]

# table to collect info for each sample
op_info = smp_info[['super_id','PolII','lib','rep']].set_index('super_id')

for _, smp in smp_info.iterrows():
    file_prefix = smp['lib']+'_'+smp['PolII']+'_'+smp['rep']+'-Ds-'
    op_info.loc[smp['super_id'],'file_prefix'] = file_prefix
    op_info.loc[smp['super_id'],'input_mtx'] = file_prefix+'TssCXed-mockBarCXonTss-sorted-grouped.tsv'
    op_info.loc[smp['super_id'],'input_idx'] = file_prefix+'TssCXed-Tss_idx.txt'
    
    # Get TSS infomation back based on TSS-Index file
    Tss_idx = dict([idx_line.split() for idx_line in open(inp_folder+file_prefix+'TssCXed-Tss_idx.txt', 'r')])
    idx_Tss = dict((v,k) for (k,v) in Tss_idx.items())

    grp = pd.read_csv(inp_folder+file_prefix+'TssCXed-mockBarCXonTss-sorted-grouped.tsv', sep='\t', index_col=False)[['position','final_umi','final_umi_count']].drop_duplicates()
    grp['TSS'] = ((grp['position']+1).apply(str)).map(idx_Tss)
        # +1 because 1) Alignment position is not the start position of the read in the BAM file but the start of the read taking into account the read strand and cigar
        #            2) when making mock SAM file, "0" was put in FLAG field, which means "mapped to the forward strand"
        #            3) UMI-tools uses 0-indexed but SAM uses 1-indexed
    grp['Barcode_Ds'] = grp['final_umi']
    grp['DNA_Count'] = grp['final_umi_count']
    
    mtx = grp[['TSS','Barcode_Ds','DNA_Count']]
    mtx.to_csv(out_folder+file_prefix+'CXed-Tss_Bar_Cnt-Mtx.txt', sep='\t', index=False) # Output-1
    op_info.loc[smp['super_id'],'n_TSS_Bar_var_BF_BarFltr'] = mtx.shape[0]
    
    # one_Barcode vs multiple_TSSs filter
    fout2 = open(out_folder+file_prefix+'CXed-BarFltr-Tss_Bar_Cnt-Mtx.txt', 'w')
    print("%s\t%s\t%s" % ("TSS", "Barcode_Ds", "DNA_Count"), file = fout2)

    fout3 = open(out_folder+file_prefix+'CXed-BarFltr_kpInfo.txt', 'w')
    print("%s\t%s" % ("Major_Bar_Count", "Total_Bar_Count"), file = fout3)

    fout4 = open(out_folder+file_prefix+'CXed-BarFltr_drpInfo.txt', 'w')
    print("%s\t%s" % ("Major_Bar_Count", "Total_Bar_Count"), file = fout4)
        
    BarNo_TSSs = 0 # to record #bar match to >1 TSSs
    Bar_TSSsNo = 0 # to record # TSS+Bar variants are related
    Bar_kept = 0 # to record #bar could be kept, where >90% reads of this barcode match to one TSS
    kept_major_bar_count = list() # to save the count of kept TSS-barcode that corresponding barcode matches to >1 TSS
    kept_sum_bar_count = list() # to save the original total count of corresponding barcode of kept TSS-barcode
    dropped_major_bar_count = list() # to save the count of dropped TSS-barcode that corresponding barcode matches to >1 TSS
    dropped_sum_bar_count = list() # to save the original total count of corresponding barcode of dropped TSS-barcode
    TSS_Bar_after = 0 # to record how many TSS_Barcode variants after filter
    output_reads = 0 # to record how many reads pass filter
    
    for Bar, group in mtx.groupby('Barcode_Ds'):
        if group.count()['TSS'] > 1: # this barcode matches to >1 TSSs
            BarNo_TSSs += 1
            Bar_TSSsNo += group.count()['TSS']
            # if #reads of major TSS-Bar of this barcode is >= 90% total reads containing this barcode, keep this major TSS-Bar, drop others
            if group.max()['DNA_Count'] >= (group.sum()['DNA_Count'] * 0.9):
                Bar_kept += 1
                kept_major_bar_count.append(group.max()['DNA_Count'])
                kept_sum_bar_count.append(group.sum()['DNA_Count'])
                kept_TSS_Bar = group.sort_values(by='DNA_Count', ascending=False).iloc[0]
                TSS_Bar_after +=1
                output_reads += kept_TSS_Bar['DNA_Count']
                print("%s\t%s\t%d" % (kept_TSS_Bar['TSS'], kept_TSS_Bar['Barcode_Ds'], kept_TSS_Bar['DNA_Count']), file = fout2)
            else: # otherwise, drop all TSS-Bar related to this barcode
                dropped_major_bar_count.append(group.max()['DNA_Count'])
                dropped_sum_bar_count.append(group.sum()['DNA_Count'])
        else: # this barcode matches to only one TSS
            TSS_Bar_Count = group.iloc[0]
            TSS_Bar_after +=1
            output_reads += TSS_Bar_Count['DNA_Count']
            print("%s\t%s\t%d" % (TSS_Bar_Count['TSS'], TSS_Bar_Count['Barcode_Ds'], TSS_Bar_Count['DNA_Count']), file = fout2)

    op_info.loc[smp['super_id'],'n_Bar_wMltTSS'] = BarNo_TSSs
    op_info.loc[smp['super_id'],'n_TSS_Bar_var_wMltTSS'] = Bar_TSSsNo
    op_info.loc[smp['super_id'],'n_Bar_wMltTSS_kept'] = Bar_kept
    op_info.loc[smp['super_id'],'n_TSS_Bar_var_AF_BarFltr'] = TSS_Bar_after
    op_info.loc[smp['super_id'],'n_ttl_DNA_Count_AF_BarFltr'] = output_reads

    for j in range(0, len(kept_major_bar_count)):
        print("%d\t%d" % (int(kept_major_bar_count[j]), int(kept_sum_bar_count[j])), file = fout3)
    
    for k in range(0, len(dropped_major_bar_count)):
        print("%d\t%d" % (int(dropped_major_bar_count[k]), int(dropped_sum_bar_count[k])), file = fout4)

op_info.reset_index().to_csv('7-BarMltTss_fltr-info.csv', sep=',', index=False, header=True, mode='w')
    
job_end = datetime.datetime.now()
print("job finished in", datetime.timedelta.total_seconds(job_end - job_start)/60, 'mins at', job_end)
