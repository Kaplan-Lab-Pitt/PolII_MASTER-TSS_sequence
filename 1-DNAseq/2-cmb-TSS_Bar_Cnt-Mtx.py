### python 3 codes ###
# remotely use Pitt HTC cluster
# python=python/anaconda3.8-2020.11 (Python 3.8.5.final.0); pandas=1.1.3; numpy=1.19.2; re=2.2.1

### To extract critical regions from reads that have expected sequence composition:
    # 111bp seq from library (w/o stuffers):
        # [27bp fixed] - [9bp TSS] - [24bp fixed] - [24bp Barcode_v2] - [27bp fixed]
        # TTCAAATTTTTCTTTTGATTTTTTTTC - TSS region - ACATTTTCAAAAGGCTAACATCAG - NNNNANNNNCNNNNTNNNNGNNNN - ATGTCTAAAGGTGAAGAATTATTCACT
# Both ends have stuff sequences: 5'-end 18-25bp; 3'-end 7-0bp;
# Combine two sequencing sets: 18179Kap_N18162 & 18179Kap_N18164

# Input-1: [DTmerge-MASTER-all_final-info_table.csv] containing information for all MASTER samples
# Input-2s: PE assembled fastq files by PEAR [*-Ds-R1R2mrgd.assembled.fastq] generated by <1-PEARmerge.slurm>
    # two data sets in two folders, with same name for same sample
        # fastq_18179Kap_N18162_L002
        # fastq_18179Kap_N18164_L002

# Output-1: [*-TSS_Bar_Cnt-Mtx.txt], sep='\t': [TSS]-[Barcode_v2]-[DNA_Count]
    # file prefix naming: library_mutant_replicate-Ds
# Output-2: [-xPrf.fastq]: reads that don't have perfect match
    # file prefix naming: library_mutant_replicate-Ds
# Output-3: [2-cmb-TSS_Bar_Cnt-Mtx-info.csv], details for processed samples

import datetime
job_start = datetime.datetime.now()
print(job_start)

import re # import Regular expression operations library
import pandas as pd
print("re version:", re.__version__)
print("pandas version:", pd.__version__)
print()

# to get info for all samples
smp_info_file = '/bgfs/ckaplan/Yunye/0-common_files/DTmerge-MASTER-all_final-info_table.csv'
smp_info = pd.read_csv(smp_info_file, na_filter= False) # w/o filling empty cells as NaN
# to only process samples with DNAseq:
smp_info = smp_info[smp_info['super_id']<=12]

# to create a table to collect info for each sample
op_info = smp_info[['super_id','PolII','lib','rep']].set_index('super_id')

# full pathname of input and output folders
fastq_file_folder1 = '/bgfs/ckaplan/Yunye/3-TSS_sequence_library/1-WT-DNAseq-TxGen_18179Kap/fastq_18179Kap_N18162_L002/'
fastq_file_folder2 = '/bgfs/ckaplan/Yunye/3-TSS_sequence_library/1-WT-DNAseq-TxGen_18179Kap/fastq_18179Kap_N18164_L002/'
mtx_op_folder = '/bgfs/ckaplan/Yunye/3-TSS_sequence_library/1-WT-DNAseq-TxGen_18179Kap/2-cmb-TSS_Bar_Cnt-Mtx/'

# to create a dictionary containing TSS sequence region information of libraries
tss_seq = {'AYR': 'A[CTAG]{6}[CT][AG]', 'BYR': '[CTG][CTAG]{6}[CT][AG]', 'ARY': 'A[CTAG]{6}[AG][CT]'}

# to process each samples
for _, smp in smp_info.iterrows():
    file_prefix = smp['lib']+'_'+smp['PolII']+'_'+smp['rep']+'-Ds-'
    op_info.loc[smp['super_id'],'file_prefix'] = file_prefix
    op_info.loc[smp['super_id'],'input_fastq'] = file_prefix+'R1R2mrgd.assembled.fastq'
    
    # to create output-1 and output-2 files
    fout1 = open(mtx_op_folder+file_prefix+'TSS_Bar_Cnt-Mtx.txt', 'w')
    print("%s\t%s\t%s" % ("TSS", "Barcode_v2", "DNA_Count"), file = fout1) # write headers
    fout2 = open(mtx_op_folder+file_prefix+'xPrf.fastq', 'w')
    
    line_num = 0
    counted_reads = 0 # to record how many reads have expected sequence composition
    TSS_Bar_counts = dict() # to save TSS_Barcode variants
    
    for dataset in [fastq_file_folder1, fastq_file_folder2]:
        for line in open(dataset+file_prefix+'R1R2mrgd.assembled.fastq', 'r'):
            line_num += 1 # which line is in processing    
            ln_read = line_num % 4  # which line of each read: 1-identifier; 2-sequence; 3-'+'; 4-quality values
            
            if ln_read == 1:
                identifier_line = line.rstrip()
            elif ln_read == 2:
                seq_line = line.rstrip()
            elif ln_read == 3:
                line3 = line.rstrip()
            elif ln_read == 0:
                quality_line = line.rstrip()                
                # if perfectly matching to expected seq:
                if re.search('TTCAAATTTTTCTTTTGATTTTTTTTC'+tss_seq[smp['lib']]+\
                             'ACATTTTCAAAAGGCTAACATCAG[CTAG]{4}A[CTAG]{4}C[CTAG]{4}T[CTAG]{4}G[CTAG]{4}ATGTCTAAAGGTGAAGAATTATTCACT',\
                             seq_line):
                    counted_reads +=1
                    lib_start_pos = seq_line.find('TTCAAATTTTTCTTTTGATTTTTTTTC') # to search where does library sequence start; (libraries have different lengths of stuffer seq)
                    tss = seq_line[(lib_start_pos+27):(lib_start_pos+27+9)] # extract 9bp TSS region - AN6YR or AN6RY or BN6YR
                    bar = seq_line[(lib_start_pos+27+9+24):(lib_start_pos+27+9+24+24)] # extract 24bp Barcode_v2 region - NNNNANNNNCNNNNTNNNNGNNNN
                    TSS_Bar = tss + '_' + bar
                    TSS_Bar_counts[TSS_Bar] = TSS_Bar_counts.get(TSS_Bar,0)+1 # count for TSS_Barcode variant
                else: # not perfectly match to expectation, output to output-2 file
                    print("%s\n%s\n%s\n%s" % (identifier_line, seq_line, line3, quality_line), file = fout2)
    
    var_num = 0 # to record how many different TSS_Bar variants
    
    # to output all TSS_Bar variants and their counts to output-1 file
    for var, count in TSS_Bar_counts.items():
        var_num += 1
        TSS_Bar_split = var.split('_')
        print("%s\t%s\t%d" % (TSS_Bar_split[0], TSS_Bar_split[1], int(count)), file = fout1)
    
    # to record details for current processing sample
    op_info.loc[smp['super_id'],'n_reads_processed'] = line_num/4
    op_info.loc[smp['super_id'],'n_reads_expected'] = counted_reads
    op_info.loc[smp['super_id'],'n_TSS_Bar_variants'] = var_num

# to output details for processed sample as output-3
op_info.reset_index().to_csv('2-cmb-TSS_Bar_Cnt-Mtx-info.csv', sep=',', index=False, header=True, mode='w')

job_end = datetime.datetime.now()
print("job finished in", datetime.timedelta.total_seconds(job_end - job_start)/60, 'mins at', job_end)