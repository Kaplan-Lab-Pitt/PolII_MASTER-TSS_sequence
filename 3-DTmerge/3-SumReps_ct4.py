### python 3 codes ###
# remotely use Pitt HTC cluster
# python=python/anaconda3.8-2020.11 (Python 3.8.5.final.0); pandas=1.1.3; numpy=1.19.2;

### After investigating reproducibility, to merge three biological replicates
# 1. sum up matched reads of reps for libraries
# 2. make summed TSS efficiency matrix
# 3. apply “ct4” = cut-off-v4:
    # TSS-seq cut-off: keep TSS variants (promoter variants) that
        # exit in 3 reps, with >=5 reads in each
        # CV <= 0.5

# Input-1:  [DTmerge-MASTER-all_final-info_table.csv] containing updated information for all MASTER samples
# Input-2s: [*-pDs-B12Cmb-pos_cnt_mtx.csv] generated by <2-SumTsB12.py>, TSS usage matrix for positions for individual reps
# Input-3s: [*-pDs_B12Cmb-reps_RNAstat.csv] generated by <2p-reps_RNAstat.py>, TSSseq stat info

# Output-1: [*-pDs_B12RepsCmb-pos_cnt_mtx-stat.csv], reps-combined TSS usage matrix, plus reps stat info
    # Output-1ct4: [*-pDs_B12RepsCmb-ct4-pos_cnt_mtx-stat.csv], reps-combined TSS usage matrix, plus reps stat info, w/ ct4 applied 
# Output-2: [*-pDs_B12RepsCmb-pos_eff_mtx-stat.csv], reps-combined TSS efficiency matrix, plus reps stat info
    # Output-2ct4: [*-pDs_B12RepsCmb-ct4-pos_eff_mtx-stat.csv], reps-combined TSS efficiency matrix, plus reps stat info, w/ ct4 applied
# Output-3: <3-SumReps_ct4-info.csv> table collecting info/stat for each sample

import datetime
job_start = datetime.datetime.now()
print(job_start)

import pandas as pd

cmn_folder = '/bgfs/ckaplan/Yunye/0-common_files/'
inp_folder_cnt = '/bgfs/ckaplan/Yunye/3-TSS_sequence_library/7-poolDs_cmbTs/2-B12Cmb-pos_cnt_mtx/'
inp_folder_stat = '/bgfs/ckaplan/Yunye/3-TSS_sequence_library/7-poolDs_cmbTs/2p-reps_RNAstat/'
out_folder_cnt = '/bgfs/ckaplan/Yunye/3-TSS_sequence_library/7-poolDs_cmbTs/3-B12RepsCmb-pos_cnt_mtx/'
out_folder_eff = '/bgfs/ckaplan/Yunye/3-TSS_sequence_library/7-poolDs_cmbTs/3-B12RepsCmb-pos_eff_mtx/'

smp_info = pd.read_csv(cmn_folder+'DTmerge-MASTER-all_final-info_table.csv', na_filter= False) # w/o filling empty cells as NaN
# to process all final samples (3x3x5=45):
smp_info = smp_info[smp_info['final'] == 'yes']

# table to collect info for each sample
op_info = pd.DataFrame()

for lib in ['AYR','BYR','ARY']:
    for pol in ['WT','E1103G','F1086S','G1097D','H1085Q']:
        cmb_cnt_mtx = pd.DataFrame()
        reps = smp_info.loc[(smp_info['lib']==lib) & (smp_info['PolII']==pol)]['rep'].tolist()
        for rep in reps:
            cmb_cnt_mtx = cmb_cnt_mtx.add(pd.read_csv(inp_folder_cnt+ lib+'_'+pol+'_'+rep+'-pDs-B12Cmb-pos_cnt_mtx.csv',\
                                                      header=0, index_col=0), fill_value = 0)
        
        ### to generate TSS efficiency matrix
            # definition: yield of a given position / the sum of yield at this position with the yield at all downstream position(s)
            # Filter: to avoid the very last a few positions being highly efficient,
                # filter out positions with >=20% efficiency and with <=5 reads PolII flux
        pos_eff_mtx = pd.DataFrame(columns=[pe for pe in range(-68,26) if pe != 0])
        
        for TSS, pos_count in cmb_cnt_mtx.iterrows():
            row_list = pos_count.tolist()
            pos_eff = [None] * 93
            for k in range(len(row_list)):
                if sum(row_list[:k]) != sum(row_list): # still polII flux remaining
                    eff = float(row_list[k])/float(sum(row_list[k:]))*100  # calculate TSS efficiency
                    if not ((eff >= 20) and (sum(row_list[k:])<=5)):
                        pos_eff[k] = eff
                    else: # filter out positions with >=20% efficiency with <=5 reads PolII flux
                        break
                else:
                    break
            if pos_eff.count(None)<93: pos_eff_mtx.loc[TSS] = pos_eff # at least one position has efficency, not been filtered out

        ### add RNAseq stat info to combined count & effcicnecy matrix
        # “ct4”: TSS that >=5 reads in each rep and CV <= 0.5
        # cnt mtx
        cmb_cnt_mtx = cmb_cnt_mtx.merge(pd.read_csv(inp_folder_stat+lib+'_'+pol+'-pDs_B12Cmb-reps_RNAstat.csv', header=0, index_col=0)\
                                          .drop(['n_exit','SD','Average'], axis=1),\
                                        left_index=True, right_index=True, how='left')
        cmb_cnt_mtx.reset_index().to_csv(out_folder_cnt+ lib+'_'+pol+'-pDs_B12RepsCmb-pos_cnt_mtx-stat.csv', index=False, header=True)
        
        cmb_cnt_mtx_ct4 = cmb_cnt_mtx[(cmb_cnt_mtx[reps[0]]>=5) & (cmb_cnt_mtx[reps[1]]>=5) & (cmb_cnt_mtx[reps[2]]>=5)\
                                       & (cmb_cnt_mtx['CV']<=0.5)]
        cmb_cnt_mtx_ct4.reset_index().to_csv(out_folder_cnt+ lib+'_'+pol+'-pDs_B12RepsCmb-ct4-pos_cnt_mtx-stat.csv', index=False, header=True)
        
        # eff mtx
        pos_eff_mtx = pos_eff_mtx.merge(pd.read_csv(inp_folder_stat+lib+'_'+pol+'-pDs_B12Cmb-reps_RNAstat.csv', header=0, index_col=0)\
                                          .drop(['n_exit','SD','Average'], axis=1),\
                                        left_index=True, right_index=True, how='left')
        pos_eff_mtx.reset_index().to_csv(out_folder_eff+ lib+'_'+pol+'-pDs_B12RepsCmb-pos_eff_mtx-stat.csv', index=False, header=True)
        
        pos_eff_mtx_ct4 = pos_eff_mtx[(pos_eff_mtx[reps[0]]>=5) & (pos_eff_mtx[reps[1]]>=5) & (pos_eff_mtx[reps[2]]>=5)\
                                       & (pos_eff_mtx['CV']<=0.5)]
        pos_eff_mtx_ct4.reset_index().to_csv(out_folder_eff+ lib+'_'+pol+'-pDs_B12RepsCmb-ct4-pos_eff_mtx-stat.csv', index=False, header=True)
 
        op_info = op_info.append({'lib':lib, 'pol':pol,\
                                  'n_TSS_cnt':cmb_cnt_mtx.shape[0], 'n_TSS_cnt_ct4':cmb_cnt_mtx_ct4.shape[0],\
                                  'n_TSS_eff':pos_eff_mtx.shape[0], 'n_TSS_eff_ct4':pos_eff_mtx_ct4.shape[0]}, ignore_index=True)

op_info[['lib','pol','n_TSS_cnt','n_TSS_cnt_ct4','n_TSS_eff','n_TSS_eff_ct4']]\
       .to_csv('3-SumReps_ct4-info.csv', index=False, header=True, mode='w')
       
job_end = datetime.datetime.now()
print("job finished in", datetime.timedelta.total_seconds(job_end - job_start)/60, 'mins at', job_end)    