### python 3 codes ###
# remotely use Pitt HTC cluster
# python=python/anaconda3.8-2020.11 (Python 3.8.5.final.0); pandas=1.1.3; numpy=1.19.2;

### After investigating reproducibility, to merge TSS-seq batch 1&2
# 1. sum up perfectly matched reads of TSS-seq batch 1&2 for libraries, based on [*-pos_cnt_mtx.csv]
# 2. make summed TSS efficiency matrix

# Input-1:  [DTmerge-MASTER-all_final-info_table.csv] containing updated information for all MASTER samples
# Input-2s: [*-pDs-pos_cnt_mtx.csv] TSS usage matrix for positions for individual batch, generated by <1-merge_poolDs_TsB12.py>

# Output-1: [*-pDs-B12Cmb-pos_cnt_mtx.csv] batches-combined TSS usage matrix
# Output-2: [*-pDs-B12Cmb-pos_eff_mtx.csv] batches-combined TSS efficiency matrix 

import datetime
job_start = datetime.datetime.now()
print(job_start)

import pandas as pd
import shutil

cmn_folder = '/bgfs/ckaplan/Yunye/0-common_files/'
inp_folder_cnt = '/bgfs/ckaplan/Yunye/3-TSS_sequence_library/7-poolDs_cmbTs/1-pos_cnt_mtx/'
inp_folder_eff = '/bgfs/ckaplan/Yunye/3-TSS_sequence_library/7-poolDs_cmbTs/1-pos_eff_mtx/'
out_folder_cnt = '/bgfs/ckaplan/Yunye/3-TSS_sequence_library/7-poolDs_cmbTs/2-B12Cmb-pos_cnt_mtx/'
out_folder_eff = '/bgfs/ckaplan/Yunye/3-TSS_sequence_library/7-poolDs_cmbTs/2-B12Cmb-pos_eff_mtx/'

smp_info = pd.read_csv(cmn_folder+'DTmerge-MASTER-all_final-info_table.csv', na_filter= False) # w/o filling empty cells as NaN
# to process all final samples (3x3x5=45):
smp_info = smp_info[smp_info['final'] == 'yes']

# for samples only have batch-1, copy and rename count and efficiency matrix
for _, smp in smp_info[smp_info['Tseq-ttlBth']=='1'].iterrows():
    file_prefix = smp['lib']+'_'+smp['PolII']+'_'+smp['rep']
    shutil.copy(inp_folder_cnt+file_prefix+'_b1-pDs-pos_cnt_mtx.csv',
                out_folder_cnt+file_prefix+'-pDs-B12Cmb-pos_cnt_mtx.csv')
    shutil.copy(inp_folder_eff+file_prefix+'_b1-pDs-pos_eff_mtx.csv',
                out_folder_eff+file_prefix+'-pDs-B12Cmb-pos_eff_mtx.csv')
    shutil.copy(inp_folder_eff+file_prefix+'_b1-pDs-pos_eff_mtx-wTtl.csv',
                out_folder_eff+file_prefix+'-pDs-B12Cmb-pos_eff_mtx-wTtl.csv')
    
# for samples have batch-1&2, sum up counts for each position, then generage efficiency matrix
for _, smp in smp_info[smp_info['Tseq-ttlBth']=='2'].iterrows():
    file_prefix = smp['lib']+'_'+smp['PolII']+'_'+smp['rep']
    cmb_cnt_mtx = pd.read_csv(inp_folder_cnt+file_prefix+'_b1-pDs-pos_cnt_mtx.csv', header=0, index_col=0)\
                    .add(pd.read_csv(inp_folder_cnt+file_prefix+'_b2-pDs-pos_cnt_mtx.csv', header=0, index_col=0),\
                         fill_value = 0)
    cmb_cnt_mtx.to_csv(out_folder_cnt+file_prefix+'-pDs-B12Cmb-pos_cnt_mtx.csv') # Output-1
    
    ### to generate TSS efficiency matrix
        # definition: yield of a given position / the sum of yield at this position with the yield at all downstream position(s)
        # Filter: to avoid the very last a few positions being highly efficient,
            # filter out positions with >=20% efficiency and with <=5 reads PolII flux
    pos_eff_mtx = pd.DataFrame(columns=[pe for pe in range(-68,26) if pe != 0])
    
    for TSS, pos_count in cmb_cnt_mtx.iterrows():
        row_list = pos_count.tolist()
        pos_eff = [None] * 93
        for k in range(len(row_list)):
            if sum(row_list[:k]) != sum(row_list): # still polII flux remaining
                eff = float(row_list[k])/float(sum(row_list[k:]))*100  # calculate TSS efficiency
                if not ((eff >= 20) and (sum(row_list[k:])<=5)):
                    pos_eff[k] = eff
                else: # filter out positions with >=20% efficiency with <=5 reads PolII flux
                    break
            else:
                break
        pos_eff_mtx.loc[TSS] = pos_eff
        
    pos_eff_mtx.to_csv(out_folder_eff+file_prefix+'-pDs-B12Cmb-pos_eff_mtx.csv') # Output-2
    
    pos_eff_mtx['mrgd_prf_ttlRNAcnt'] = cmb_cnt_mtx.sum(axis=1)
    pos_eff_mtx.to_csv(out_folder_eff+file_prefix+'-pDs-B12Cmb-pos_eff_mtx-wTtl.csv')
        
job_end = datetime.datetime.now()
print("job finished in", datetime.timedelta.total_seconds(job_end - job_start)/60, 'mins at', job_end)    